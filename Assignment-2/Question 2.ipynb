{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import string\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import re, os, operator\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "from random import randint as randi\n",
    "from math import log10\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from random import randint as randi\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTokens(fileName):\n",
    "    f = open(fileName, 'r')\n",
    "    text = PreProcessing(f.read())\n",
    "    tokens = word_tokenize(text)\n",
    "    f.close()\n",
    "    return tokens\n",
    "\n",
    "def getTestingTokens(sent):\n",
    "    text = PreProcessing(sent, False)\n",
    "    tokens = word_tokenize(text)\n",
    "    return tokens\n",
    "\n",
    "def getSentenceTokens(fileName):\n",
    "    f = open(fileName, 'r')\n",
    "    text = SentPreProcessing(f.read())\n",
    "    tokens = sent_tokenize(text)\n",
    "#     text = re.sub(r'[^\\w]', ' ', text)\n",
    "    f.close()\n",
    "    return tokens\n",
    "\n",
    "def SentPreProcessing(text):\n",
    "    header = text.find(\"\\n\\n\")\n",
    "    header = text.find(\"\\n\\n\", header+4)\n",
    "    text = text[header:]\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[\\w\\$\\.-]+@[\\w\\.-]+\\.\\w+', ' ', text)\n",
    "#     for i in string.punctuation:\n",
    "#         cmd = '\\b' + str(i) + '\\b'\n",
    "#         text = text.replace(cmd, '\\b\\b')\n",
    "    return text\n",
    "\n",
    "def PreProcessing(text, flag=True):\n",
    "    if flag:\n",
    "        header = text.find(\"\\n\\n\")\n",
    "        header = text.find(\"\\n\\n\", header+4)\n",
    "        text = text[header:]\n",
    "    text = text.strip()\n",
    "    text = text.rstrip()\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[\\w\\$\\.-]+@[\\w\\.-]+\\.\\w+', ' ', text)\n",
    "#     text = re.sub()\n",
    "    for i in string.punctuation:\n",
    "        text = text.replace(i, '')\n",
    "#     for i in string.punctuation:\n",
    "#         cmd = '\\b' + str(i) + '\\b'\n",
    "#         text = text.replace(cmd, '\\b\\b')\n",
    "#     text = re.sub(r'[0-9]', '', text)\n",
    "    text = re.sub(r'[^\\w]', ' ', text)\n",
    "    return text\n",
    "\n",
    "def getUniGramCount(tokens, uniDic):\n",
    "    uni = uniDic\n",
    "    for tkn in tokens:\n",
    "        if tkn in uni:\n",
    "            uni[tkn] += 1\n",
    "        else:\n",
    "            uni[tkn] = 1\n",
    "    return uni, len(tokens)\n",
    "\n",
    "def getBiGramCount(tokens, bidic):\n",
    "    BiGramTable = bidic\n",
    "    BigramCount = 0\n",
    "    for i in range(len(tokens)-1):\n",
    "        word = tokens[i]\n",
    "        nextWord = tokens[i+1]\n",
    "        if word in BiGramTable:\n",
    "            if nextWord in BiGramTable[word]:\n",
    "                BiGramTable[word][nextWord] += 1\n",
    "            else:\n",
    "                BiGramTable[word][nextWord] = 1\n",
    "                BigramCount += 1\n",
    "        else:\n",
    "            BiGramTable[word] = {}\n",
    "            BiGramTable[word][nextWord] = 1\n",
    "            BigramCount += 1\n",
    "    return BiGramTable, BigramCount\n",
    "\n",
    "def getTriGramCount(tokens, tridic):\n",
    "    TriGramTable = tridic\n",
    "    TrigramCount = 0\n",
    "    for i in range(len(tokens)-2):\n",
    "        word = tokens[i]\n",
    "        nextWord = tokens[i+1]\n",
    "        nextnextWord = tokens[i+2]\n",
    "        if word in TriGramTable:\n",
    "            if nextWord in TriGramTable[word]:\n",
    "                if nextnextWord in TriGramTable[word][nextWord]:\n",
    "                    TriGramTable[word][nextWord][nextnextWord] += 1\n",
    "                else:\n",
    "                    TriGramTable[word][nextWord][nextnextWord] = 1\n",
    "                    TrigramCount += 1\n",
    "            else:\n",
    "                TriGramTable[word][nextWord] = {}\n",
    "                TriGramTable[word][nextWord][nextnextWord] = 1\n",
    "                TrigramCount += 1\n",
    "        else:\n",
    "            TriGramTable[word] = {}\n",
    "            TriGramTable[word][nextWord] = {}\n",
    "            TriGramTable[word][nextWord][nextnextWord] = 1\n",
    "            TrigramCount += 1\n",
    "    return TriGramTable, TrigramCount\n",
    "\n",
    "def predictUniProbability(tokens, UniArr, tokensAll, priors):\n",
    "    totalTokens = tokensAll[0] + tokensAll[1]\n",
    "    Vocab = list(set(totalTokens))\n",
    "    probs = np.zeros(2)\n",
    "    for j in range(2):\n",
    "        proba = 0\n",
    "        for i in range(len(tokens)):\n",
    "            if tokens[i] in UniArr[j]:\n",
    "                proba += log10((UniArr[j][tokens[i]] + 1)/(len(tokensAll[j]) + len(Vocab)))\n",
    "            else:\n",
    "                proba += log10(1/(len(tokensAll[j]) + len(Vocab)))\n",
    "        probs[j] = proba\n",
    "    return probs\n",
    "\n",
    "def predictBiProbability(tokens, UniArr, BiArr, tokensAll, priors):\n",
    "    tokens = [\"<Start>\"] + tokens\n",
    "    totalTokens = tokensAll[0] + tokensAll[1]\n",
    "    Vocab = list(set(totalTokens))\n",
    "    probs = np.zeros(2)\n",
    "    for j in range(2):\n",
    "        proba = 0\n",
    "        for i in range(len(tokens)-1):\n",
    "            word = tokens[i]\n",
    "            nextWord = tokens[i+1]\n",
    "            if word in BiArr[j]:\n",
    "                if nextWord in BiArr[j][word]:\n",
    "                    proba += log10((BiArr[j][word][nextWord] + 1)/(UniArr[j][word] + len(Vocab)))\n",
    "                else:\n",
    "                    proba += log10(1/(UniArr[j][word] + len(Vocab)))\n",
    "            else:\n",
    "                proba += log10(1/(len(Vocab)))\n",
    "        probs[j] = proba\n",
    "    return probs\n",
    "\n",
    "def predictTriProbability(tokens, BiArr, TriArr, tokensAll, priors):\n",
    "    tokens = [\"<Start>\"] + tokens\n",
    "    totalTokens = tokensAll[0] + tokensAll[1]\n",
    "    Vocab = list(set(totalTokens))\n",
    "    probs = np.zeros(2)\n",
    "    for j in range(2):\n",
    "        proba = 0\n",
    "        for i in range(len(tokens)-2):\n",
    "            word = tokens[i]\n",
    "            nextWord = tokens[i+1]\n",
    "            nextnextWord = tokens[i+2]\n",
    "            if word in TriArr[j]:\n",
    "                if nextWord in TriArr[j][word]:\n",
    "                    if nextnextWord in TriArr[j][word][nextWord]:\n",
    "                        proba += log10((1 + TriArr[j][word][nextWord][nextnextWord])/ (BiArr[j][word][nextWord] + len(Vocab)))\n",
    "                    else:\n",
    "                        proba += log10(1/(BiArr[j][word][nextWord] + len(Vocab)))\n",
    "                else:\n",
    "                    proba += log10(1/len(Vocab))\n",
    "            else:\n",
    "                proba += log10(1/len(Vocab))\n",
    "        probs[j] = proba\n",
    "    return probs\n",
    "\n",
    "def getUniSentence(UniArr, tokensAll, priors, MinWordLength=5, MaxWordLength=9):\n",
    "    totalTokens = tokensAll[0] + tokensAll[1]\n",
    "    Vocab = list(set(totalTokens))\n",
    "    for i in range(2):\n",
    "        SortedUniDic = sorted(UniArr[i].items(), key=lambda kv: kv[1], reverse=True)\n",
    "        proba = 0\n",
    "        index = 0\n",
    "        Keys = []\n",
    "        for key, value in SortedUniDic:\n",
    "            if (key != \"<Start>\"):\n",
    "                Keys.append(key)\n",
    "        Sentence = []\n",
    "#         print(len(Keys), Keys)\n",
    "        while(len(Sentence) < MaxWordLength):\n",
    "            temp = log10((UniArr[i][Keys[index]] + 1)/(len(tokensAll) + len(Vocab)))\n",
    "            if (len(Sentence) > MinWordLength and (temp + proba) < proba ):\n",
    "                break\n",
    "            if ((Keys[index] == \".\" or Keys[index] == \"!\" or Keys[index] == \"?\") and len(Sentence) > MinWordLength):\n",
    "                Sentence.append(Keys[index])\n",
    "                proba += temp\n",
    "                break\n",
    "            if (Keys[index] == \".\" or Keys[index] == \"!\" or Keys[index] == \"?\"):\n",
    "                index += 1\n",
    "                continue\n",
    "            Sentence.append(Keys[index])\n",
    "            proba += temp\n",
    "            index += 1\n",
    "        print(\"Sentence Generation using UniGram Methods [Class {}]\".format(i+1), end= \": \")\n",
    "        for w in Sentence:\n",
    "            print(w, end=\" \")\n",
    "        print(\"\\n\")\n",
    "        print(proba)\n",
    "        print()\n",
    "        \n",
    "def getNextWord(prevWord, bidic):    \n",
    "    Keys = bidic[prevWord].keys()\n",
    "    MaxWord = \"\"\n",
    "    count = 0\n",
    "    for k in Keys:\n",
    "        if bidic[prevWord][k] > count:\n",
    "            count = bidic[prevWord][k]\n",
    "            MaxWord = k\n",
    "    return MaxWord\n",
    "    \n",
    "    \n",
    "def getBiSentence(BiArr, UniArr, tokensAll, MinWordLength=5, MaxWordLength=9):\n",
    "    totalTokens = tokensAll[0] + tokensAll[1]\n",
    "    Vocab = list(set(totalTokens))\n",
    "    for i in range(2):\n",
    "        proba = 0\n",
    "        Sentence = []\n",
    "        prevWord = \"<Start>\"\n",
    "        while(len(Sentence) < MaxWordLength):\n",
    "            word = getNextWord(prevWord, BiArr[i])\n",
    "            temp = log10((BiArr[i][prevWord][word] + 1)/(UniArr[i][prevWord] + len(Vocab)))\n",
    "            if (len(Sentence) > MinWordLength and (temp + proba) < proba ):\n",
    "                break\n",
    "            if ((word == \".\" or word == '?' or word == \"!\") and len(Sentence) > MinWordLength):\n",
    "                Sentence.append(word)\n",
    "                proba += temp\n",
    "                break\n",
    "            Sentence.append(word)\n",
    "            proba += temp\n",
    "            prevWord = word\n",
    "        print(\"Sentence Generation using BiGram Methods [Class {}]\".format(i+1), end= \": \")\n",
    "        for w in Sentence:\n",
    "            print(w, end=\" \")\n",
    "        print(\"\\n\")\n",
    "        print(proba)\n",
    "        print()   \n",
    "    \n",
    "def getTriSentence(TriArr, BiArr, tokensAll, MinWordLength=5, MaxWordLength=9):\n",
    "    totalTokens = tokensAll[0] + tokensAll[1]\n",
    "    Vocab = list(set(totalTokens))\n",
    "    for i in range(2):\n",
    "        proba = 0\n",
    "        Sentence = []\n",
    "        word = \"<Start>\"\n",
    "        nextWord, nextnextWord = getInitialWords(TriArr[i])\n",
    "        Sentence.append(nextWord)\n",
    "        Sentence.append(nextnextWord)\n",
    "        while(len(Sentence) < MaxWordLength):\n",
    "            nextnextnextWord = getNextWordTri(nextWord, nextnextWord, TriArr[i])\n",
    "            temp = log10((TriArr[i][nextWord][nextnextWord][nextnextnextWord] + 1)/(BiArr[i][nextWord][nextnextWord] + len(Vocab)))\n",
    "            if (len(Sentence) > MinWordLength and (temp + proba) < proba ):\n",
    "                break\n",
    "            if ((word == \".\" or word == '?' or word == \"!\") and len(Sentence) > MinWordLength):\n",
    "                Sentence.append(word)\n",
    "                proba += temp\n",
    "                break\n",
    "            Sentence.append(nextnextnextWord)\n",
    "            nextWord = nextnextWord\n",
    "            nextnextWord = nextnextnextWord\n",
    "            proba += temp\n",
    "        print(\"Sentence Generation using TriGram Methods [Class {}]\".format(i+1), end= \": \")\n",
    "        for w in Sentence:\n",
    "            print(w, end=\" \")\n",
    "        print(\"\\n\")\n",
    "        print(proba)\n",
    "        print()   \n",
    "        \n",
    "def getNextWordTri(w1, w2, tridic):\n",
    "    count = 0\n",
    "    word = \"\"\n",
    "    for k in tridic[w1][w2].keys():\n",
    "        if (count < tridic[w1][w2][k]):\n",
    "            count = tridic[w1][w2][k]\n",
    "            word = k\n",
    "    return word\n",
    "        \n",
    "def getInitialWords(tridic):\n",
    "    SW = \"<Start>\"\n",
    "    nextWord = \"\"\n",
    "    nextnextWord = \"\"\n",
    "    count = 0\n",
    "    for k in tridic[SW].keys():\n",
    "        for k2 in tridic[SW][k].keys():\n",
    "            if tridic[SW][k][k2] > count:\n",
    "                count = tridic[SW][k][k2]\n",
    "                nextWord = k\n",
    "                nextnextWord = k2\n",
    "    return nextWord, nextnextWord\n",
    "        \n",
    "def ConsiderUniStartWord(unidic, sent):\n",
    "    SW = \"<Start>\"\n",
    "    if SW not in unidic:\n",
    "        unidic[SW] = len(sent)\n",
    "    unidic[SW] += len(sent)\n",
    "    return unidic\n",
    "\n",
    "def ConsiderBiStartWord(bidic, sent):\n",
    "    SW = \"<Start>\"\n",
    "    if SW not in bidic:\n",
    "        bidic[SW] = {}\n",
    "    for i in range(len(sent)):\n",
    "        s = sent[i]\n",
    "        words = word_tokenize(s)\n",
    "        if (len(words) < 1):\n",
    "            continue\n",
    "        if not re.match(\"^[a-zA-Z0-9_]*$\", words[0]):\n",
    "            continue\n",
    "        if words[0] in bidic[\"<Start>\"]:\n",
    "            bidic[\"<Start>\"][words[0]] += 1\n",
    "        else:\n",
    "            bidic[\"<Start>\"][words[0]] = 1\n",
    "        \n",
    "#         for j in range(len(words)-1):\n",
    "#             w = words[j]\n",
    "#             if w in BiDic[\"<Start>\"]:\n",
    "#                 BiDic[\"<Start>\"][w] += 1\n",
    "#             else:\n",
    "#                 BiDic[\"<Start>\"][w] = 1\n",
    "    return bidic\n",
    "\n",
    "def ConsiderTriStartWord(tridic, sent):\n",
    "    SW = \"<Start>\"\n",
    "    if SW not in tridic:\n",
    "        tridic[SW] = {}\n",
    "    for i in range(len(sent)):\n",
    "        s = sent[i]\n",
    "        words = word_tokenize(s)\n",
    "        if (len(words) < 2):\n",
    "            continue\n",
    "        if ((not re.match(\"^[a-zA-Z0-9_]*$\", words[0])) or (not re.match(\"^[a-zA-Z0-9_]*$\", words[1]))):\n",
    "            continue\n",
    "        w1 = words[0]\n",
    "        w2 = words[1]\n",
    "        if w1 in tridic[\"<Start>\"]:\n",
    "            if w2 in tridic[\"<Start>\"][w1]:\n",
    "                tridic[\"<Start>\"][w1][w2] += 1\n",
    "            else:\n",
    "                tridic[\"<Start>\"][w1][w2] = 1\n",
    "        else:\n",
    "            tridic[\"<Start>\"][w1] = {}\n",
    "            tridic[\"<Start>\"][w1][w2] = 1\n",
    "#         for j in range(len(words)-2):\n",
    "#             w = words[j]\n",
    "#             nextW = words[j+1]\n",
    "#             if w in TriDic[\"<Start>\"]:\n",
    "#                 if nextW in TriDic[\"<Start>\"][w]:\n",
    "#                     TriDic[\"<Start>\"][w][nextW] += 1\n",
    "#                 else:\n",
    "#                     TriDic[\"<Start>\"][w][nextW] = 1\n",
    "#             else:\n",
    "#                 TriDic[\"<Start>\"][w] = {}\n",
    "#                 TriDic[\"<Start>\"][w][nextW] = 1\n",
    "    return tridic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5 0.5]\n"
     ]
    }
   ],
   "source": [
    "UniArr = []\n",
    "BiArr = []\n",
    "TriArr = []\n",
    "TokensAll = []\n",
    "priors = np.zeros(2)\n",
    "Class = [\"20_newsgroups/rec.sport.baseball/\", \"20_newsgroups/rec.motorcycles/\"]\n",
    "for i in range(2):\n",
    "    \n",
    "    foldersName = os.listdir(Class[i])\n",
    "    tokens = []\n",
    "    UniDic = {}\n",
    "    BiDic = {}\n",
    "    TriDic = {}\n",
    "    priors[i] = len(foldersName)\n",
    "    for j in range(len(foldersName)):\n",
    "        tkn = getTokens(Class[i] + foldersName[j])\n",
    "        sent = getSentenceTokens(Class[i] + foldersName[j])\n",
    "        UniDic = ConsiderUniStartWord(UniDic, sent)\n",
    "        BiDic = ConsiderBiStartWord(BiDic, sent)\n",
    "        TriDic = ConsiderTriStartWord(TriDic, sent)\n",
    "        UniDic, uni_count = getUniGramCount(tkn, UniDic)\n",
    "        BiDic, bi_count = getBiGramCount(tkn, BiDic)\n",
    "        TriDic, tri_count = getTriGramCount(tkn, TriDic)\n",
    "        tokens += tkn\n",
    "        \n",
    "    TokensAll.append(tokens)\n",
    "    UniArr.append(UniDic)\n",
    "    BiArr.append(BiDic)\n",
    "    TriArr.append(TriDic)\n",
    "#     print(TriDic)\n",
    "priors /= (priors[0]+priors[1])\n",
    "print(priors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Generation using UniGram Methods [Class 1]: the to a and of in \n",
      "\n",
      "-4.79695062760876\n",
      "\n",
      "Sentence Generation using UniGram Methods [Class 2]: the a to i and of \n",
      "\n",
      "-4.980958775324477\n",
      "\n",
      "Sentence Generation using BiGram Methods [Class 1]: i think that the game in \n",
      "\n",
      "-13.272894857703374\n",
      "\n",
      "Sentence Generation using BiGram Methods [Class 2]: i was a few weeks i \n",
      "\n",
      "-15.074211353175436\n",
      "\n",
      "Sentence Generation using TriGram Methods [Class 1]: i do not know what it \n",
      "\n",
      "-13.203913269137793\n",
      "\n",
      "Sentence Generation using TriGram Methods [Class 2]: if you want to go left \n",
      "\n",
      "-13.029959819975991\n",
      "\n"
     ]
    }
   ],
   "source": [
    "getUniSentence(UniArr, TokensAll, priors)\n",
    "getBiSentence(BiArr, UniArr, TokensAll)\n",
    "getTriSentence(TriArr, BiArr, TokensAll)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting probability And Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a sentence: How about a Geeky temporary tatoo?\n",
      "UniGram Probability: [-22.81233518 -20.54741237]\n",
      "BiGram Probability: [-21.95600977 -20.39957009]\n",
      "TriGram Probability: [-20.36166876 -18.38628068]\n",
      "\n",
      "UniGram Perplexity: [6339.51251297 2658.08416097]\n",
      "BiGram Perplexity: [4563.88783333 2511.47204032]\n",
      "TriGram Perplexity: [2475.2066304  1159.79201026]\n"
     ]
    }
   ],
   "source": [
    "sentence = str(input(\"Enter a sentence: \"))\n",
    "tokens = getTestingTokens(sentence)\n",
    "\n",
    "uniProb = predictUniProbability(tokens, UniArr, TokensAll, priors)\n",
    "print(\"UniGram Probability:\", uniProb)\n",
    "\n",
    "biProb = predictBiProbability(tokens, UniArr, BiArr, TokensAll, priors)\n",
    "print(\"BiGram Probability:\", biProb)\n",
    "\n",
    "triProb = predictTriProbability(tokens, BiArr, TriArr, TokensAll, priors)\n",
    "print(\"TriGram Probability:\", triProb)\n",
    "\n",
    "print()\n",
    "\n",
    "for i in range(2):\n",
    "    uniProb[i] = uniProb[i] * (-1/len(tokens))\n",
    "    uniProb[i] = 10**uniProb[i]\n",
    "print(\"UniGram Perplexity:\", uniProb)\n",
    "\n",
    "for i in range(2):\n",
    "    biProb[i] = biProb[i] * (-1/len(tokens))\n",
    "    biProb[i] = 10**biProb[i]\n",
    "print(\"BiGram Perplexity:\", biProb)\n",
    "\n",
    "for i in range(2):\n",
    "    triProb[i] = triProb[i]*(-1/len(tokens))\n",
    "    triProb[i] = 10**triProb[i]\n",
    "print(\"TriGram Perplexity:\", triProb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Good Turing Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UniGTSmoothing(UniArr):\n",
    "    NUni = []\n",
    "    for i in range(2):\n",
    "        count = np.ones(10000, dtype=np.int64)\n",
    "        for w in UniArr[i]:\n",
    "            count[UniArr[i][w]] += 1\n",
    "        NUni.append(count)\n",
    "    return NUni\n",
    "\n",
    "def BiGTSmoothing(BiArr):\n",
    "    NBi = []\n",
    "    for i in range(2):\n",
    "        count = np.ones(10000, dtype=np.int64)\n",
    "        for w in BiArr[i]:\n",
    "            for w2 in BiArr[i][w]:\n",
    "                count[BiArr[i][w][w2]] += 1\n",
    "        NBi.append(count)\n",
    "    return NBi\n",
    "\n",
    "def TriGTSmoothing(TriArr):\n",
    "    NTri = []\n",
    "    for i in range(2):\n",
    "        count = np.ones(10000, dtype=np.int64)\n",
    "        for w in TriArr[i]:\n",
    "            for w2 in TriArr[i][w]:\n",
    "                for w3 in TriArr[i][w][w2]:\n",
    "                    count[TriArr[i][w][w2][w3]] += 1\n",
    "        NTri.append(count)\n",
    "    return NTri\n",
    "\n",
    "def predictUniProbGT(tokens, UniArr, tokensAll, NUni):\n",
    "    totalTokens = tokensAll[0] + tokensAll[1]\n",
    "    Vocab = list(set(totalTokens))\n",
    "    probs = np.zeros(2)\n",
    "    for j in range(2):\n",
    "        proba = 0\n",
    "        for i in range(len(tokens)):\n",
    "            if tokens[i] in UniArr[j]:\n",
    "                c = UniArr[j][tokens[i]] + 1\n",
    "                cStar = (c*NUni[j][c])/ NUni[j][c-1]\n",
    "                proba += log10(cStar/len(tokensAll[j]))\n",
    "            else:\n",
    "                proba += log10(NUni[j][1]/len(tokensAll[j]))\n",
    "#         print(probs)\n",
    "        probs[j] = proba\n",
    "    return probs\n",
    "\n",
    "def predictBiProbGT(tokens, UniArr, BiArr, tokensAll, NBi, NUni):\n",
    "    tokens = [\"<Start>\"] + tokens\n",
    "    totalTokens = tokensAll[0] + tokensAll[1]\n",
    "    Vocab = list(set(totalTokens))\n",
    "    probs = np.zeros(2)\n",
    "    for j in range(2):\n",
    "        proba = 0\n",
    "        for i in range(len(tokens)-1):\n",
    "            word = tokens[i]\n",
    "            nextWord = tokens[i+1]\n",
    "            if word in BiArr[j]:\n",
    "                if nextWord in BiArr[j][word]:\n",
    "                    c = BiArr[j][word][nextWord] + 1\n",
    "                    cStar = (c*NBi[j][c])/ (NBi[j][c-1]*len(tokensAll))\n",
    "                    proba += log10(cStar)\n",
    "                else:\n",
    "                    proba += log10(NBi[j][1]/len(tokensAll))\n",
    "        probs[j] = proba\n",
    "    return probs\n",
    "\n",
    "def predictTriProbGT(tokens, BiArr, TriArr, tokensAll, NTri, NBi):\n",
    "    tokens = [\"<Start>\"] + tokens\n",
    "    totalTokens = tokensAll[0] + tokensAll[1]\n",
    "    Vocab = list(set(totalTokens))\n",
    "    probs = np.zeros(2)\n",
    "    for j in range(2):\n",
    "        proba = 0\n",
    "        for i in range(len(tokens)-2):\n",
    "            word = tokens[i]\n",
    "            nextWord = tokens[i+1]\n",
    "            nextnextWord = tokens[i+2]\n",
    "            if word in TriArr[j]:\n",
    "                if nextWord in TriArr[j][word]:\n",
    "                    if nextnextWord in TriArr[j][word][nextWord]:\n",
    "                        c = TriArr[j][word][nextWord][nextnextWord] + 1\n",
    "                        cStar = (c*NTri[j][c])/(NTri[j][c-1]*len(tokensAll))\n",
    "                        proba += log10(cStar)\n",
    "                    else:\n",
    "                        proba += log10(NTri[j][1]/len(tokensAll))\n",
    "        probs[j] = proba\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUni = UniGTSmoothing(UniArr)\n",
    "NBi = BiGTSmoothing(BiArr)\n",
    "NTri = TriGTSmoothing(TriArr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a sentence: the sale of the Orioles to anyone is likely\n",
      "UniGram Probability: [-25.08234787 -21.39245556]\n",
      "BiGram Probability: [18.12941897 16.02243749]\n",
      "TriGram Probability: [23.27938822 18.31311241]\n"
     ]
    }
   ],
   "source": [
    "sentence = str(input(\"Enter a sentence: \"))\n",
    "tokens = getTestingTokens(sentence)\n",
    "\n",
    "uniProb = predictUniProbGT(tokens, UniArr, TokensAll, NUni)\n",
    "print(\"UniGram Probability:\", uniProb)\n",
    "\n",
    "biProb = predictBiProbGT(tokens, UniArr, BiArr, TokensAll, NBi, NUni)\n",
    "print(\"BiGram Probability:\", biProb)\n",
    "\n",
    "triProb = predictTriProbGT(tokens, BiArr, TriArr, TokensAll, NTri, NBi)\n",
    "print(\"TriGram Probability:\", triProb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UniArrGT = []\n",
    "# BiArrGT = []\n",
    "# TriArrGT = []\n",
    "# for i in range(2):\n",
    "#     UniArrGT.append(copy.deepcopy(UniArr[i]))\n",
    "#     BiArrGT.append(copy.deepcopy(BiArr[i]))\n",
    "#     TriArrGT.append(copy.deepcopy(TriArr[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
