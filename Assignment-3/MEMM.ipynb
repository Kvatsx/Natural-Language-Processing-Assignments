{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import re, os, pickle, operator\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from math import log10, exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_obj(obj, name):\n",
    "    with open('obj/'+ name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name):\n",
    "    with open('obj/' + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def get_sentence(filename):\n",
    "    file = open(filename, 'r', encoding=\"utf8\")\n",
    "    data = file.read()\n",
    "    sent = data.split(\"\\n\\n\")\n",
    "    print(\"No of Sentences: {}\".format(len(sent)))\n",
    "    return sent\n",
    "\n",
    "def POSTagFreq(sents):\n",
    "    POS = {}\n",
    "    for i in range(len(sents)):\n",
    "        sent = sents[i].split(\"\\n\")\n",
    "        for j in range(len(sent)):\n",
    "            word, tag, bio = sent[j].split(\"\\t\")\n",
    "            if tag in POS:\n",
    "                POS[tag] += 1\n",
    "            else:\n",
    "                POS[tag] = 1\n",
    "    POS = sorted(POS.items(), key=lambda x: x[1], reverse=True)\n",
    "    return POS[0]\n",
    "\n",
    "def Train(sentences):\n",
    "    MostOccTag = POSTagFreq(sents)\n",
    "    WordCount = {}\n",
    "    BIOTagFreq = {}\n",
    "    F1 = {}\n",
    "    F2 = {}\n",
    "    F3 = {}\n",
    "    F4 = {}\n",
    "    F5 = {}\n",
    "    for i in range(len(sentences)):\n",
    "        sent = sentences[i].split(\"\\n\")\n",
    "        for j in range(len(sent)):\n",
    "            word, tag, bio = sent[j].split(\"\\t\")\n",
    "            \n",
    "            #Feature 1\n",
    "            if j == 0:\n",
    "                if bio in F1:\n",
    "                    if word in F1[bio]:\n",
    "                        F1[bio][word] += 1\n",
    "                    else:\n",
    "                        F1[bio][word] = 1\n",
    "                else:\n",
    "                    F1[bio] = {}\n",
    "                    F1[bio][word] = 1\n",
    "            #Feature 2\n",
    "            if j == (len(sent)-1):\n",
    "                if bio in F2:\n",
    "                    if word in F2[bio]:\n",
    "                        F2[bio][word] += 1\n",
    "                    else:\n",
    "                        F2[bio][word] = 1\n",
    "                else:\n",
    "                    F2[bio] = {}\n",
    "                    F2[bio][word] = 1\n",
    "                    \n",
    "            # Feature 3\n",
    "            if j > 0:\n",
    "                _, prev_tag, _ = sent[j-1].split(\"\\t\")\n",
    "                if bio in F3:\n",
    "                    if word in F3[bio]:\n",
    "                        if prev_tag in F3[bio][word]:\n",
    "                            F3[bio][word][prev_tag] += 1\n",
    "                        else:\n",
    "                            F3[bio][word][prev_tag] = 1\n",
    "                    else:\n",
    "                        F3[bio][word] = {}\n",
    "                        F3[bio][word][prev_tag] = 1\n",
    "                else:\n",
    "                    F3[bio] = {}\n",
    "                    F3[bio][word] = {}\n",
    "                    F3[bio][word][prev_tag] = 1\n",
    "            \n",
    "            # Feature 4\n",
    "            if len(sent)-1 > j:\n",
    "                _, next_tag, _ = sent[j+1].split(\"\\t\")\n",
    "                if next_tag == MostOccTag:\n",
    "                    if bio in F4:\n",
    "                        if word in F4[bio]:\n",
    "                            if next_tag in F4[bio][word]:\n",
    "                                F4[bio][word][next_tag] += 1\n",
    "                            else:\n",
    "                                F4[bio][word][next_tag] = 1\n",
    "                        else:\n",
    "                            F4[bio][word] = {}\n",
    "                            F4[bio][word][next_tag] = 1\n",
    "                    else:\n",
    "                        F4[bio] = {}\n",
    "                        F4[bio][word] = {}\n",
    "                        F4[bio][word][next_tag] = 1\n",
    "                    \n",
    "            # Feature 5\n",
    "            if bio in F5:\n",
    "                if word in F5[bio]:\n",
    "                    F5[bio][word] += 1\n",
    "                else:\n",
    "                    F5[bio][word] = 1\n",
    "            else:\n",
    "                F5[bio] = {}\n",
    "                F5[bio][word] = 1\n",
    "            \n",
    "            # Update Denominator\n",
    "            if bio in  WordCount:\n",
    "                if word in WordCount[bio]:\n",
    "                    WordCount[bio][word] += 1\n",
    "                else:\n",
    "                    WordCount[bio][word] = 1\n",
    "            else:\n",
    "                WordCount[bio] = {}\n",
    "                WordCount[bio][word] = 1\n",
    "            \n",
    "            if bio in BIOTagFreq:\n",
    "                BIOTagFreq[bio] += 1\n",
    "            else:\n",
    "                BIOTagFreq[bio] = 1\n",
    "\n",
    "    save_obj(MostOccTag, \"MostOccTag\")\n",
    "    save_obj(WordCount, \"WordCount\")\n",
    "    save_obj(BIOTagFreq, \"BIOTagFreq\")\n",
    "    save_obj(F1, \"F1\")\n",
    "    save_obj(F2, \"F2\")\n",
    "    save_obj(F3, \"F3\")\n",
    "    save_obj(F4, \"F4\")\n",
    "    save_obj(F5, \"F5\")\n",
    "    \n",
    "def predict(sentences):\n",
    "    MostOccTag = load_obj(\"MostOccTag\")\n",
    "    WordCount = load_obj(\"WordCount\")\n",
    "    BIOTagFreq = load_obj(\"BIOTagFreq\")\n",
    "    F1 = load_obj(\"F1\")\n",
    "    F2 = load_obj(\"F2\")\n",
    "    F3 = load_obj(\"F3\")\n",
    "    F4 = load_obj(\"F4\")\n",
    "    F5 = load_obj(\"F5\")\n",
    "    \n",
    "    bioTag = []\n",
    "    for i in range(len(sentences)):\n",
    "        sent = sentences[i].split(\"\\n\")\n",
    "        PredTag = []\n",
    "        for j in range(len(sent)):\n",
    "            word, tag, _ = sent[j].split(\"\\t\")\n",
    "            proba = np.zeros(3)\n",
    "            Tags = [\"I-NP\", \"B-NP\", \"O\"]\n",
    "            for idx, bio in enumerate(Tags):\n",
    "                wf = 0\n",
    "                if j == 0:\n",
    "                    if bio in F1:\n",
    "                        if word in F1[bio]:\n",
    "                            wf += (F1[bio][word]/WordCount[bio][word])\n",
    "                if j == len(sent)-1:\n",
    "                    if bio in F2:\n",
    "                        if word in F2[bio]:\n",
    "                            wf += (F2[bio][word]/WordCount[bio][word])\n",
    "                if j > 0:\n",
    "                    _, prev_tag, _ = sent[j-1].split(\"\\t\")\n",
    "                    if bio in F3:\n",
    "                        if word in F3[bio]:\n",
    "                            if prev_tag in F3[bio][word]:\n",
    "                                wf += (F3[bio][word][prev_tag]/WordCount[bio][word])\n",
    "                if j < len(sent)-1:\n",
    "                    if bio in F4:\n",
    "                        if word in F4[bio]:\n",
    "                            if MostOccTag in F4[bio][word]:\n",
    "                                wf += (F4[bio][word][MostOccTag]/WordCount[bio][word])\n",
    "                if bio in F5:\n",
    "                    if word in F5[bio]:\n",
    "                        wf += (F5[bio][word]/BIOTagFreq[bio])\n",
    "                proba[idx] = exp(wf)\n",
    "            PredTag.append(Tags[np.argmax(proba)])\n",
    "        bioTag.append(PredTag)\n",
    "    return bioTag\n",
    "\n",
    "\n",
    "def save_output(sents, bioTag):\n",
    "    file = open(\"output.np\", \"w\")\n",
    "    Tags = [\"I-NP\", \"B-NP\", \"O\"]\n",
    "    CorrectCount = {}\n",
    "    Counts = {}\n",
    "    for i in range(len(Tags)):\n",
    "        Counts[Tags[i]] = 0\n",
    "        CorrectCount[Tags[i]] = 0\n",
    "    for i in range(len(sents)):\n",
    "        sent = sents[i].split(\"\\n\")\n",
    "        for j in range(len(sent)):\n",
    "            word, tag, bio = sent[j].split(\"\\t\")\n",
    "            file.write(word + \"\\t\" + tag + \"\\t\" + bio + \"\\t\" + bioTag[i][j] + \"\\n\")\n",
    "            Counts[bio] += 1\n",
    "            if (bio == bioTag[i][j]):\n",
    "                CorrectCount[bio] += 1\n",
    "        file.write(\"\\n\")\n",
    "    for i in range(len(Tags)):\n",
    "        print(\"{} : {}\".format(Tags[i], (CorrectCount[Tags[i]]/Counts[Tags[i]])*100 ))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of Sentences: 3428\n",
      "No of Sentences: 694\n"
     ]
    }
   ],
   "source": [
    "Data = \"Data/\"\n",
    "sents = get_sentence(Data + \"train.np\")\n",
    "test_sents = get_sentence(Data + \"dev.np\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(sents[0])\n",
    "Train(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I-NP : 94.91803278688525\n",
      "B-NP : 93.13422966718096\n",
      "O : 87.8259131279093\n"
     ]
    }
   ],
   "source": [
    "bioTag = predict(sents)\n",
    "save_output(sents, bioTag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I-NP : 87.79304769603881\n",
      "B-NP : 72.96612852168408\n",
      "O : 78.98019647590831\n"
     ]
    }
   ],
   "source": [
    "bioTag = predict(test_sents)\n",
    "save_output(test_sents, bioTag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
