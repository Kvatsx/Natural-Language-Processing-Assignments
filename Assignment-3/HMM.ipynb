{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import re, os, pickle\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from math import log10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_obj(obj, name):\n",
    "    with open('obj/'+ name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name):\n",
    "    with open('obj/' + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def get_sentence(filename):\n",
    "    file = open(filename, 'r')\n",
    "    data = file.read()\n",
    "    sent = data.split(\"\\n\\n\")\n",
    "    print(\"No of Sentences: {}\".format(len(sent)))\n",
    "    return sent\n",
    "\n",
    "def HMM_Train(sentences):\n",
    "    Words = []\n",
    "    nTagFreq = {}\n",
    "    A = {}\n",
    "    B = {}\n",
    "    nTagFreq[\"<Start>\"] = len(sentences)\n",
    "    \n",
    "    for i in range(len(sentences)):\n",
    "        sent = sentences[i].split(\"\\n\")\n",
    "        prev_tag = \"<Start>\"\n",
    "        for j in range(len(sent)):\n",
    "            word, tag = sent[j].split(\"\\t\")\n",
    "            if tag in B:\n",
    "                if word in B[tag]:\n",
    "                    B[tag][word] += 1\n",
    "                else:\n",
    "                    B[tag][word] = 1\n",
    "            else:\n",
    "                B[tag] = {}\n",
    "                B[tag][word] = 1\n",
    "            \n",
    "            if tag in nTagFreq:\n",
    "                nTagFreq[tag] += 1\n",
    "            else:\n",
    "                nTagFreq[tag] = 1\n",
    "            \n",
    "            if prev_tag in A:\n",
    "                if tag in A[prev_tag]:\n",
    "                    A[prev_tag][tag] += 1\n",
    "                else:\n",
    "                    A[prev_tag][tag] = 1\n",
    "            else:\n",
    "                A[prev_tag] = {}\n",
    "                A[prev_tag][tag] = 1\n",
    "                \n",
    "            prev_tag = tag\n",
    "            if word not in Words:\n",
    "                Words.append(word)\n",
    "        if (prev_tag in A):\n",
    "            if (\"<End>\" in A[prev_tag]):\n",
    "                A[prev_tag][\"<End>\"] += 1\n",
    "            else:\n",
    "                A[prev_tag][\"<End>\"] = 1\n",
    "        else:\n",
    "            A[prev_tag] = {}\n",
    "            A[prev_tag][\"<End>\"] = 1\n",
    "    save_obj(A, \"A\")\n",
    "    save_obj(B, \"B\")\n",
    "    save_obj(nTagFreq, \"nTagFreq\")\n",
    "    save_obj(Words, \"Words\")\n",
    "    \n",
    "def Viterbi(sentence):\n",
    "    Words = load_obj(\"Words\")\n",
    "    nTagFreq = load_obj(\"nTagFreq\")\n",
    "    A = load_obj(\"A\")\n",
    "    B = load_obj(\"B\")\n",
    "    VocabSize = len(Words)\n",
    "    StartCount = nTagFreq[\"<Start>\"]\n",
    "    del(nTagFreq[\"<Start>\"])\n",
    "    Tags = list(nTagFreq.keys())\n",
    "    TagSize = len(list(Tags))\n",
    "    \n",
    "    sent = sentence.split(\"\\n\")\n",
    "    Vt = np.zeros((TagSize, len(sent)))\n",
    "    VtStar = np.zeros((TagSize, len(sent)), dtype=np.int64)\n",
    "    POSTag = ['NULL' for i in range(len(sent))]\n",
    "    \n",
    "    # Start State Handling\n",
    "    prev_tag = \"<Start>\"\n",
    "    for i in range(TagSize):\n",
    "        w = sent[0]\n",
    "        p=0\n",
    "        if (Tags[i] in A[prev_tag]):\n",
    "            p += log10((A[prev_tag][Tags[i]] + 1)/(StartCount + TagSize))\n",
    "        else:\n",
    "            p += log10(1/(StartCount + TagSize))\n",
    "        if (w in B[Tags[i]]):\n",
    "            p += log10((B[Tags[i]][w] + 1)/(nTagFreq[Tags[i]] + VocabSize))\n",
    "        else:\n",
    "            p += log10(1/(nTagFreq[Tags[i]] + VocabSize))\n",
    "        Vt[i, 0] = p\n",
    "        VtStar[i, 0] = -1\n",
    "    \n",
    "    # Mid States\n",
    "    for i in range(1, len(sent)):\n",
    "        for j in range(TagSize):\n",
    "            probs = np.zeros(TagSize)\n",
    "            for k in range(TagSize):\n",
    "                p = 0\n",
    "                w = sent[i]\n",
    "                if (Tags[k] in A):\n",
    "                    if (Tags[j] in A[Tags[k]]):\n",
    "                        p += log10((A[Tags[k]][Tags[j]] + 1)/(nTagFreq[Tags[k]] + TagSize))\n",
    "                    else:\n",
    "                        p += log10(1/(nTagFreq[Tags[k]] + TagSize))\n",
    "                else:\n",
    "                    p += log10(1/TagSize)\n",
    "                if (w in B[Tags[j]]):\n",
    "                    p += log10((B[Tags[j]][w] + 1)/(nTagFreq[Tags[j]] + VocabSize))\n",
    "                else:\n",
    "                    p += log10(1/(nTagFreq[Tags[j]] + VocabSize))\n",
    "                probs[k] = Vt[k, i-1] + p\n",
    "            Vt[j, i] = np.amax(probs)\n",
    "            VtStar[j, i] = np.argmax(probs)\n",
    "    \n",
    "    # EndState \n",
    "    prob = np.zeros(TagSize)\n",
    "    for i in range(TagSize):\n",
    "        prob[i] = Vt[i, len(sent)-1]\n",
    "        if (Tags[i] in A):\n",
    "            if (\"<End>\" in A[Tags[i]]):\n",
    "                prob[i] += log10((A[Tags[i]][\"<End>\"] + 1)/(nTagFreq[Tags[i]] + TagSize))\n",
    "            else:\n",
    "                prob[i] += log10(1/(nTagFreq[Tags[i]] + TagSize))\n",
    "        else:\n",
    "            prob[i] += log10(1/TagSize)\n",
    "    \n",
    "    POSTag[len(sent)-1] = Tags[np.argmax(prob)]\n",
    "    index = np.argmax(Vt[:, len(sent)-1])\n",
    "    for i in range(len(sent)-2, -1, -1):\n",
    "        POSTag[i] = Tags[index]\n",
    "        index = VtStar[index, i]\n",
    "    return POSTag\n",
    "\n",
    "\n",
    "def ViterbiValidation(sentence):\n",
    "    Words = load_obj(\"Words\")\n",
    "    nTagFreq = load_obj(\"nTagFreq\")\n",
    "    A = load_obj(\"A\")\n",
    "    B = load_obj(\"B\")\n",
    "    VocabSize = len(Words)\n",
    "    StartCount = nTagFreq[\"<Start>\"]\n",
    "    del(nTagFreq[\"<Start>\"])\n",
    "    Tags = list(nTagFreq.keys())\n",
    "    TagSize = len(list(Tags))\n",
    "    \n",
    "    sent = sentence.split(\"\\n\")\n",
    "    Vt = np.zeros((TagSize, len(sent)))\n",
    "    VtStar = np.zeros((TagSize, len(sent)), dtype=np.int64)\n",
    "    POSTag = ['NULL' for i in range(len(sent))]\n",
    "    \n",
    "    # Start State Handling\n",
    "    prev_tag = \"<Start>\"\n",
    "    for i in range(TagSize):\n",
    "        w = sent[0].split(\"\\t\")[0]\n",
    "        p=0\n",
    "        if (Tags[i] in A[prev_tag]):\n",
    "            p += log10((A[prev_tag][Tags[i]] + 1)/(StartCount + TagSize))\n",
    "        else:\n",
    "            p += log10(1/(StartCount + TagSize))\n",
    "        if (w in B[Tags[i]]):\n",
    "            p += log10((B[Tags[i]][w] + 1)/(nTagFreq[Tags[i]] + VocabSize))\n",
    "        else:\n",
    "            p += log10(1/(nTagFreq[Tags[i]] + VocabSize))\n",
    "        Vt[i, 0] = p\n",
    "        VtStar[i, 0] = -1\n",
    "    \n",
    "    # Mid States\n",
    "    for i in range(1, len(sent)):\n",
    "        for j in range(TagSize):\n",
    "            probs = np.zeros(TagSize)\n",
    "            for k in range(TagSize):  # prev_tag\n",
    "                p = 0\n",
    "                w = sent[i].split(\"\\t\")[0]\n",
    "                if (Tags[k] in A):\n",
    "                    if (Tags[j] in A[Tags[k]]):\n",
    "                        p += log10((A[Tags[k]][Tags[j]] + 1)/(nTagFreq[Tags[k]] + TagSize))\n",
    "                    else:\n",
    "                        p += log10(1/(nTagFreq[Tags[k]] + TagSize))\n",
    "                else:\n",
    "                    p += log10(1/TagSize)\n",
    "                if (w in B[Tags[j]]):\n",
    "                    p += log10((B[Tags[j]][w] + 1)/(nTagFreq[Tags[j]] + VocabSize))\n",
    "                else:\n",
    "                    p += log10(1/(nTagFreq[Tags[j]] + VocabSize))\n",
    "                probs[k] = Vt[k, i-1] + p\n",
    "            Vt[j, i] = np.amax(probs)\n",
    "            VtStar[j, i] = np.argmax(probs)\n",
    "    \n",
    "    # EndState \n",
    "    prob = np.zeros(TagSize)\n",
    "    for i in range(TagSize):\n",
    "        prob[i] = Vt[i, len(sent)-1]\n",
    "        if (Tags[i] in A):\n",
    "            if (\"<End>\" in A[Tags[i]]):\n",
    "                prob[i] += log10((A[Tags[i]][\"<End>\"] + 1)/(nTagFreq[Tags[i]] + TagSize))\n",
    "            else:\n",
    "                prob[i] += log10(1/(nTagFreq[Tags[i]] + TagSize))\n",
    "        else:\n",
    "            prob[i] += log10(1/TagSize)\n",
    "    \n",
    "    POSTag[len(sent)-1] = Tags[np.argmax(prob)]\n",
    "    index = VtStar[np.argmax(prob), len(sent)-1]\n",
    "    for i in range(len(sent)-2, -1, -1):\n",
    "        POSTag[i] = Tags[index]\n",
    "        index = VtStar[index, i]\n",
    "    return POSTag\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of Sentences: 15711\n"
     ]
    }
   ],
   "source": [
    "Data = \"Data/\"\n",
    "sents = get_sentence(Data + \"Training set_HMM.txt\")\n",
    "train = sents[:int(len(sents)*0.99)]\n",
    "test = sents[int(len(sents)*.99):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HMM_Train(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of Sentences: 2\n"
     ]
    }
   ],
   "source": [
    "sents = get_sentence(\"Test.in\")\n",
    "file = open(\"Test.out\", 'w')\n",
    "for i in range(len(sents)):\n",
    "    Tags = Viterbi(sents[i])\n",
    "    lines = sents[i].split(\"\\n\")\n",
    "    for j in range(len(lines)):\n",
    "        file.write(lines[j] + \"\\t\" + Tags[j] + \"\\n\")\n",
    "    file.write(\"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0ed84256e8743c5bd18e247dc360f3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=158), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.7943925233645\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for i in tqdm(range(len(test))):\n",
    "    Tags = ViterbiValidation(test[i])\n",
    "    lines = test[i].split(\"\\n\")\n",
    "    for j in range(len(lines)):\n",
    "        if (lines[j].split(\"\\t\")[1] == Tags[j]):\n",
    "#             print(lines[j].split(\"\\t\")[1], Tags[j], \"+\")\n",
    "            correct += 1\n",
    "#         else:\n",
    "#             print(lines[j].split(\"\\t\")[1], Tags[j], \"-\")\n",
    "        total += 1\n",
    "print(\"Accuracy: {}\".format((correct/total)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
